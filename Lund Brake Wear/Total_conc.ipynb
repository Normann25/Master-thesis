{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da219876",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('../Style.mplstyle')\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import scipy\n",
    "import matplotlib.dates as mdates\n",
    "from datetime import datetime\n",
    "sys.path.append('..')\n",
    "from read_data_functions import *\n",
    "from plot_functions import *\n",
    "from calculations import *\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "352f65f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to read file with separation: \t\n",
      "Failed to read file with separation: ,\n",
      "Failed to read file with separation: ,\n"
     ]
    }
   ],
   "source": [
    "# Define paths to data\n",
    "parent_path = '../../../../'\n",
    "path = 'L:/PG-Nanoteknologi/PROJEKTER/2024 Laura og Nan/Lund/'\n",
    "\n",
    "# Read data\n",
    "NS_SMPS = read_SMPS(path, parent_path, [0, 0])\n",
    "OPS_APS = read_OPS(path, parent_path, 0)\n",
    "CPC = read_CPC(f'{path}CPC/', parent_path)\n",
    "\n",
    "# Define dictionary keys relavent for each experiment\n",
    "CPC_dict_keys = ['test7_CPC', 'test8_CPC', 'test9_CPC', 'test10_CPC']\n",
    "NS_dict_keys = ['2024-10-16_NanoScan', '2024-10-16_NanoScan', '2024-10-17_NanoScan', '2024-10-17_NanoScan']\n",
    "dict_keys = ['Exp1', 'Exp2', 'Exp3', 'Exp4']\n",
    "APS_dict_keys = ['20241016_APS', '20241016_APS_2_exp', '20241017_APS', '20241017_APS']\n",
    "SMPS_dict_keys = ['20241016_SMPS', '20241016_SMPS_2_exp', '20241017_SMPS', '20241017_SMPS']\n",
    "\n",
    "# Define relevant df keys for each instrument\n",
    "NS_bins = NS_SMPS['2024-10-21_NanoScan'].keys()[3:16].to_list()\n",
    "OPS_bins = OPS_APS['Exp1'].keys()[1:17].to_list()\n",
    "OPS_mid_point = [0.337, 0.419, 0.522, 0.650, 0.809, 1.007, 1.254, 1.562, 1.944, 2.421, 3.014, 3.752, 4.672, 5.816, 7.241, 9.015]\n",
    "APS_bins = OPS_APS['20241016_APS'].keys()[1:53].to_list()\n",
    "SMPS_bins = NS_SMPS['20241016_SMPS'].keys()[4:117].to_list()\n",
    "CPC_key = [CPC['test7_CPC'].keys()[1]]\n",
    "\n",
    "# Subtract HEPA filter measurements from NanoScan data\n",
    "NS_bg_mean, NS_bg_std, NS_bg_error = bin_mean(['2024/10/21 11:45:00', '2024/10/21 14:10:00'], \n",
    "                                              NS_SMPS['2024-10-21_NanoScan'], NS_bins, 'Time', 0.1)\n",
    "for key in NS_dict_keys:\n",
    "    df = NS_SMPS[key]\n",
    "    for i, bin in enumerate(NS_bins):\n",
    "        df[bin] = df[bin] - NS_bg_mean[i]\n",
    "    NS_SMPS[key] = df\n",
    "\n",
    "# Change OPS df keys from bin cut-point to bin mid-point\n",
    "for dict_key in dict_keys:\n",
    "    for old_key, new_key in zip(OPS_bins, OPS_mid_point):\n",
    "        OPS_APS[dict_key] = OPS_APS[dict_key].rename(columns = {old_key: new_key})\n",
    "\n",
    "# Convert from dN/dlogDp to N for APS\n",
    "APS_bin_mean = [(0.486968 + 0.523)/2]\n",
    "for key in OPS_APS['20241016_APS'].keys()[2:53]:\n",
    "    APS_bin_mean.append(float(key))\n",
    "APS_cut_point = np.concatenate(([0.486968], (np.array(APS_bin_mean)[1:]+np.array(APS_bin_mean)[:-1])/2, [20.53]))\n",
    "\n",
    "for key in APS_dict_keys[1:3]:\n",
    "    for i, bin in enumerate(APS_bins):\n",
    "        bin_width = np.log10(APS_cut_point[i+1]) - np.log10(APS_cut_point[i])\n",
    "        OPS_APS[key][bin] = pd.to_numeric(OPS_APS[key][bin]) * bin_width\n",
    "\n",
    "# Convert from mass to number for APS data from first experiment\n",
    "APS_number = pd.DataFrame({'Time': OPS_APS['20241016_APS']['Time']})\n",
    "for i, key in enumerate(APS_bins):\n",
    "    OPS_APS['20241016_APS'][key] = pd.to_numeric(OPS_APS['20241016_APS'][key], errors='coerce') * 1.2 # Correct density\n",
    "    APS_number[key] = OPS_APS['20241016_APS'][key] / ((1.2 / 10**6) * (np.pi / 6) * APS_bin_mean[i]**3 * 10**6) # in #/cm**3\n",
    "OPS_APS['20241016_APS'] = APS_number\n",
    "\n",
    "# Convert from dN/dlogDp to N for SMPS\n",
    "SMPS_bin_mean = []\n",
    "for key in NS_SMPS['20241016_SMPS'].keys()[4:117]:\n",
    "    SMPS_bin_mean.append(float(key) / 1000)\n",
    "SMPS_cut_point = np.concatenate(([0.017], (np.array(SMPS_bin_mean)[1:]+np.array(SMPS_bin_mean)[:-1])/2, [1.0]))\n",
    "\n",
    "for key in SMPS_dict_keys[:3]:\n",
    "    for i, bin in enumerate(SMPS_bins):\n",
    "        bin_width = np.log10(SMPS_cut_point[i+1]) - np.log10(SMPS_cut_point[i])\n",
    "        NS_SMPS[key][bin] = pd.to_numeric(NS_SMPS[key][bin]) * bin_width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20814736",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_bg(data_dict, dict_keys, new_keys, df_keys, bg_timestamps):\n",
    "    new_dict = {}\n",
    "\n",
    "    for i, key in enumerate(dict_keys):\n",
    "        df = data_dict[key]\n",
    "        new_df = pd.DataFrame({'Time': df['Time']})\n",
    "\n",
    "        if len(df_keys) == 1:\n",
    "            bg_time, bg_conc = time_filtered_arrays(df, None, bg_timestamps[i], df_keys[0])\n",
    "            new_df[df_keys[0]] = df[df_keys[0]] - bg_conc.mean()\n",
    "            new_df[df_keys[0]][new_df[df_keys[0]] < 0] = 0\n",
    "\n",
    "        else:\n",
    "            background, std, e = bin_mean(bg_timestamps[i], df, df_keys, 'Time', None)\n",
    "\n",
    "            for bin, bg in zip(df_keys, background):\n",
    "                new_df[bin] = pd.to_numeric(df[bin], errors='coerce') - bg\n",
    "                new_df[bin][new_df[bin] < 0] = 0\n",
    "        \n",
    "        if new_keys != None:\n",
    "            new_dict[new_keys[i]] = new_df\n",
    "        else:\n",
    "            new_dict[key] = new_df\n",
    "\n",
    "    return new_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b315f4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamps_BG = [['2024-10-16 10:17:00', '2024-10-16 10:26:00'],\n",
    "                 ['2024-10-16 14:43:00', '2024-10-16 14:53:00'],\n",
    "                 ['2024-10-17 09:48:00', '2024-10-17 09:59:00'],\n",
    "                 ['2024-10-17 14:10:00', '2024-10-17 14:20:00']]\n",
    "\n",
    "OPS = remove_bg(OPS_APS, dict_keys, None, OPS_mid_point, timestamps_BG)\n",
    "APS = remove_bg(OPS_APS, APS_dict_keys, dict_keys, APS_bins, timestamps_BG)\n",
    "NS = remove_bg(NS_SMPS, NS_dict_keys, dict_keys, NS_bins, timestamps_BG)\n",
    "SMPS = remove_bg(NS_SMPS, SMPS_dict_keys, dict_keys, SMPS_bins, timestamps_BG)\n",
    "CPC = remove_bg(CPC, CPC_dict_keys, dict_keys, CPC_key, timestamps_BG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41eb94a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamps_exp = [['2024-10-16 10:26:00', '2024-10-16 12:26:00'],\n",
    "                  ['2024-10-16 14:54:00', '2024-10-16 15:34:00'],\n",
    "                  ['2024-10-17 10:00:00', '2024-10-17 12:00:00'],\n",
    "                  ['2024-10-17 14:17:00', '2024-10-17 14:57:00']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "da216310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([0.337, 0.419, 0.522,  0.65, 0.809, 1.007, 1.254, 1.562, 1.944, 2.421,\n",
      "       3.014, 3.752, 4.672, 5.816, 7.241, 9.015],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(OPS['Exp1'].keys()[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb188ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NanoScan\n",
      "Experiment 1:\n",
      "PN0.1 = 18005.8334 and PN0.3 = 29945.301399999997\n",
      "Experiment 2:\n",
      "PN0.1 = 37743.57462 and PN0.3 = 54626.821480000006\n",
      "Experiment 3:\n",
      "PN0.1 = 3423.0923272727273 and PN0.3 = 5719.987336363636\n",
      "Experiment 4:\n",
      "PN0.1 = 6575.4585400000005 and PN0.3 = 10632.94964\n"
     ]
    }
   ],
   "source": [
    "# Total concentrations\n",
    "for i, key in enumerate(dict_keys):\n",
    "    print(f'Experiment {i+1}:')\n",
    "    start, end = pd.to_datetime(timestamps_exp[i][0]), pd.to_datetime(timestamps_exp[i][1])\n",
    "\n",
    "    # NanoScan\n",
    "    time_NS = pd.to_datetime(NS[key]['Time'])\n",
    "    time_filter_NS = (time_NS >= start) & (time_NS <= end)\n",
    "    df_NS = NS[key][time_filter_NS]\n",
    "\n",
    "    PN01_array_NS = df_NS.iloc[:,1:10].sum(axis = 1)\n",
    "    PN03_array_NS = df_NS.iloc[:,1:13].sum(axis = 1)\n",
    "    PN01_NS = PN01_array_NS.sum()\n",
    "    PN03_NS = PN03_array_NS.sum()\n",
    "    print(f'NanoScan:   PN0.1 = {PN01_NS:.2f} and PN0.3 = {PN03_NS:.2f}')\n",
    "\n",
    "    # SMPS\n",
    "    time_SMPS = pd.to_datetime(SMPS[key]['Time'])\n",
    "    time_filter_SMPS = (time_SMPS >= start) & (time_SMPS <= end)\n",
    "    df_SMPS = SMPS[key][time_filter_SMPS]\n",
    "\n",
    "    PN01_array_SMPS = df_SMPS.iloc[:,1:51].sum(axis = 1)\n",
    "    PN03_array_SMPS = df_SMPS.iloc[:,1:81].sum(axis = 1)\n",
    "    PN1_array_SMPS = df_SMPS.iloc[:,1:].sum(axis = 1)\n",
    "    PN01_SMPS = PN01_array_SMPS.sum()\n",
    "    PN03_SMPS = PN03_array_SMPS.sum()\n",
    "    PN1_SMPS = PN1_array_SMPS.sum()\n",
    "    print(f'SMPS:   PN0.1 = {PN01_SMPS:.2f} and PN0.3 = {PN03_SMPS:.2f} and PN1 = {PN1_SMPS:.2f}')\n",
    "\n",
    "    # CPC\n",
    "    time_CPC = pd.to_datetime(CPC[key]['Time'])\n",
    "    time_filter_CPC = (time_CPC >= start) & (time_CPC <= end)\n",
    "    df_CPC = CPC[key][time_filter_CPC]\n",
    "\n",
    "    PN1_CPC = df_CPC[CPC_key[0]].sum()\n",
    "    print(f'CPC: PN1 = {PN1_CPC:.2f}')\n",
    "\n",
    "    # OPS\n",
    "    time_OPS = pd.to_datetime(OPS[key]['Time'])\n",
    "    time_filter_OPS = (time_OPS >= start) & (time_OPS <= end)\n",
    "    df_OPS = OPS[key][time_filter_OPS]\n",
    "\n",
    "    PN1_array_OPS = df_OPS.iloc[:,1:7].sum(axis = 1)\n",
    "    PN25_array_OPS = df_OPS.iloc[:,1:11].sum(axis = 1)\n",
    "    PN10_array_OPS = df_OPS.iloc[:,1:].sum(axis = 1)\n",
    "    PN1_OPS = PN1_array_OPS.sum()\n",
    "    PN25_OPS = PN25_array_OPS.sum()\n",
    "    PN10_OPS = PN10_array_OPS.sum()\n",
    "    print(f'OPS:   PN1 = {PN1_OPS:.2f} and PN2.5 = {PN25_OPS:.2f} and PN10 = {PN10_OPS:.2f}')\n",
    "\n",
    "    # APS\n",
    "    time_APS = pd.to_datetime(OPS[key]['Time'])\n",
    "    time_filter_OPS = (time_OPS >= start) & (time_OPS <= end)\n",
    "    df_OPS = OPS[key][time_filter_OPS]\n",
    "\n",
    "    PN1_array_APS = df_OPS.iloc[:,1:7].sum(axis = 1)\n",
    "    PN25_array_APS = df_OPS.iloc[:,1:11].sum(axis = 1)\n",
    "    PN10_array_OPS = df_OPS.iloc[:,1:].sum(axis = 1)\n",
    "    PN1_OPS = PN1_array_OPS.sum()\n",
    "    PN25_OPS = PN25_array_OPS.sum()\n",
    "    PN10_OPS = PN10_array_OPS.sum()\n",
    "    print(f'OPS:   PN1 = {PN1_OPS:.2f} and PN2.5 = {PN25_OPS:.2f} and PN10 = {PN10_OPS:.2f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
